# [Large Multimodal Agents: A Survey](https://arxiv.org/pdf/2402.15116.pdf)
簡易まとめ：自分の言葉でまとめたもの。  
GPT翻訳：GPTで翻訳した全文。  

## GPT翻訳
### Abstruct
大規模言語モデル（LLM）は、テキストベースのAIエージェントを駆動する上で卓越した性能を発揮し、人間に似た意思決定や推論能力をこれらに与えています。  
同時に、これらのLLMで駆動されるAIエージェントを多モーダル領域へと拡張する研究の新たなトレンドが現れています。  
この拡張により、AIエージェントは多様な多モーダルユーザークエリを解釈し、応答することが可能となり、より複雑で微妙なタスクを処理できるようになります。  
本論文では、大規模多モーダルエージェント（略称LMAs）と呼ばれるLLM駆動の多モーダルエージェントに焦点を当てた体系的なレビューを行います。  
まず、LMAsを開発する上での必須コンポーネントを紹介し、現在の研究を4つの異なるタイプに分類します。  
その後、複数のLMAsを統合する協調フレームワークをレビューし、集合的な効果を高めます。  
この分野における重要な課題の一つは、異なるLMAs間での効果的な比較を妨げる、既存研究における多様な評価方法です。  
そのため、これらの評価方法論をまとめ、ギャップを埋めるための包括的なフレームワークを確立します。  
このフレームワークは、評価を標準化し、より意味のある比較を促進することを目的としています。  
レビューを締めくくるにあたり、LMAsの広範な応用を強調し、将来の研究方向性を提案します。  
私たちの議論は、この急速に進化する分野における将来の研究に対する貴重な洞察とガイドラインを提供することを目的としています。  
最新のリソースリストはhttps://github.com/jun0wanan/awesome-large-multimodal-agentsで利用可能です。  

### 1. Introduction
エージェントとは、環境を知覚し、これらの知覚に基づいて特定の目標を達成するための決定を下す能力を持つシステムです[56]。  
狭いドメインでは熟練しているものの、初期のエージェント[35, 50]は適応性と一般化が欠けており、人間の知能との顕著な差異が強調されます。  
最近の大規模言語モデル（LLM）の進歩は、このギャップを埋め始めています。  
ここでは、LLMがコマンド解釈、知識の同化[36, 78]、および人間の推論や学習の模倣[21, 66]の能力を高めています。  
これらのエージェントは、主要な意思決定ツールとしてLLMを使用し、記憶などの重要な人間らしい特徴でさらに強化されています。  
この強化により、彼らはさまざまな自然言語処理タスクを扱い、言語を使用して環境と対話することができます[40, 38]。  

![図1](../../../data/12.png)

実際のシナリオでは、テキストを超えた情報がしばしば関与し、視覚的側面に重点を置いた複数のモダリティを包含しています。  
その結果、LLMで駆動されるインテリジェントエージェントの次の進化のステップは、特に視覚データを含む多モーダル情報を処理し生成する能力を獲得することです。  
この能力は、これらのエージェントが人間レベルの知能を反映したより堅牢なAIエンティティへと進化するために不可欠です。  
この能力を備えたエージェントは、私たちの論文では大規模多モーダルエージェント（LMA）として言及されています。  
通常、これらは言語のみのエージェントよりも複雑な課題に直面します。  
例えば、ウェブ検索を例に取ると、LMAはまず検索バーを通じて関連情報を探すためのユーザー要件の入力が必要です。  
その後、マウスクリックやスクロールを通じてウェブページにナビゲートし、リアルタイムのウェブページコンテンツをブラウズします。  
最後に、LMAは多モーダルデータ（例えば、テキスト、動画、画像）を処理し、ウェブ記事、動画レポート、ソーシャルメディアの更新から重要な情報を抽出し、この情報を統合してユーザーのクエリに応答するという多段階の推論を行う必要があります。  
既存のLMAに関する研究が孤立して行われたため、既存のフレームワークを要約し比較することにより、この分野をさらに進展させる必要があることに注意しています。  
LLMで駆動されるエージェントに関連するいくつかの調査が存在します[60, 42, 49]が、そのうちのいくつかは多モーダル側面に焦点を当てています。  

本論文では、LMAの主要な発展をまとめることでこのギャップを埋めることを目指しています。  
まず、コアコンポーネントについての導入（§2）を行い、既存研究に対する新たな分類法を提案します（§3）。  
さらに、既存の協力フレームワークについて議論します（§4）。  
評価に関しては、LMAの性能を評価するための既存の方法論を概説し、その後に包括的な要約を提供します（§5）。  
次に、アプリケーションセクションでは、多モーダルエージェントとそれに関連するタスクの広範な実世界アプリケーションについての徹底的な概観を提供します（§6）。  
この作業を締めくくり、LMAに対する可能な将来の方向性について議論し、有益な研究ガイダンスを提供することを提案します。  

### 2 The Core Components of LMAs
このセクションでは、知覚、計画、行動、および記憶を含むLMAの四つの核心要素について詳述します。  

#### 知覚(Perception)
知覚は、人間が環境情報を収集し解釈することを可能にする複雑な認知プロセスです。  
LMAにおける知覚コンポーネントは、主に多様な環境からの多モーダル情報を処理することに焦点を当てています。  
表1に示されているように、異なるタスクのLMAは様々なモダリティを含んでいます。  
これら異なるモダリティからタスク完了に最も有益な鍵となる情報を抽出することが求められ、これによってより効果的な計画とタスクの実行が促進されます。  

![図1](../../../data/11.png)

多モーダル情報の処理に関する初期の研究[57, 43, 70, 9]は、画像や音声をテキスト説明に変換するための単純な相関モデルやツールに頻繁に依存していました。  
しかし、この変換アプローチは、特に複雑なモダリティ（例えば、ビデオ）に関して、大量の無関係で冗長な情報を生成する傾向があります。  
入力の長さの制約と共に、LLMは効果的に関連情報を抽出し計画に役立てることにおいて頻繁に課題に直面しています。  
この問題を解決するため、最近の研究[71, 47]では、洗練されたデータタイプを扱うために設計されたサブタスクツールの概念を導入しました。  
実世界に似た環境（つまり、オープンワールドゲーム）において、[51]は非テキストモダリティ情報を処理するための新しい方法を提案しました。  
このアプローチは、環境から重要な視覚ボキャブラリーを抽出することから始まり、その後GPTモデルを使用してこのボキャブラリーを一連の記述的な文章にさらに洗練させます。  
LLMが環境内の視覚モダリティを知覚するとき、それらを使用して最も関連性の高い記述的な文章を取得し、これによって周囲の理解を効果的に高めます。  

#### 計画(Planning)
計画者は、人間の脳の機能に似て、LMAにおいて中心的な役割を果たします。  
彼らは現在のタスクについて深い推論を行い、それに応じた計画を立てる責任があります。  
言語のみのエージェントと比べて、LMAはより複雑な環境で動作するため、合理的な計画を立てることがより困難になります。  
私たちは、計画者を4つの視点（モデル、形式、検査＆反省、および計画方法）から詳述します：  

モデル  
表1に示されているように、既存の研究は異なるモデルを計画者として採用しています。  
その中でも、最も人気のあるものはGPT-3.5やGPT-4 [43, 41, 9, 30, 57, 51]です。  
しかし、これらのモデルは公開されていないため、一部の研究ではLLaMA [67]やLLaVA [23]のようなオープンソースモデルの使用にシフトし始めています。  
後者は複数のモダリティの情報を直接処理することができ、より最適な計画を立てる能力を高めます。  

形式  
計画者によって立てられた計画をどのように形式化するかを表します。  
表1に示されているように、2つの形式化方法があります。  
最初のものは自然言語です。  
例えば、[41]では、得られた計画内容は「最初に行ったことは、画像内の少年のポーズを分析するためにOpenCVのopenposeコントロールモデルを使用することでした...」であり、計画されたのは「OpenCVのopenposeコントロールモデルを使用する」ことです。  
2番目のものはプログラムの形式で、「image_patch = ImagePatch(image)」と[43]で説明されているように、計画の実行にImagePatch関数を呼び出します。[9]  
のように、ハイブリッド形式も存在します。  

検査＆反省  
複雑な多モーダル環境でLMAが一貫して意味のあるタスク完了計画を立てることは難しいです。  
このコンポーネントは、堅牢性と適応性を高めることを目指しています。  
いくつかの研究方法[51, 52]は、計画を導くために多モーダル状態を含む成功体験を長期記憶に保存します。  
計画プロセス中、彼らはまず関連する経験を取り出し、計画者が不確実性を減らすために慎重な検討を助けます。  
さらに、[12]は同じタスクを実行する際に異なる状態で人間によって作られた計画を利用します。  
類似の状態に遭遇したとき、計画者はこれらの「標準答え」を熟考のために参照し、より合理的な計画につながります。  
さらに、[71]はモンテカルロのようなより複雑な計画方法を採用し、最適な計画戦略を見つけるために計画検索の範囲を拡大します。  

計画方法  
既存の計画戦略は、表1に示されているように、動的計画と静的計画の2つのタイプに分類できます。  
前者[57, 43, 70, 30, 41]は、Chain of Thought (CoT) [80]に似て、初期入力に基づいて目標を一連のサブプランに分解することを指し、プロセス中にエラーが発生しても計画は再構成されません。  
後者[9, 25, 51, 71]は、各計画が現在の環境情報またはフィードバックに基づいて形成されることを意味し、計画にエラーが検出された場合、再計画のために元の状態に戻ります[12]。  

行動  
多モーダルエージェントシステムにおける行動コンポーネントは、計画者によって立案された計画や決定を実行する責任があります。  
これらの計画をツールの使用、身体運動、インターフェースとの相互作用などの特定の行動に変換し、エージェントがその目標を達成し、正確かつ効率的に環境と相互作用できるようにします。  
私たちの議論は、タイプとアプローチの2つの側面に焦点を当てています。

表1の行動は、ツールの使用（T）、身体的行動（E）、仮想行動（V）の3つのカテゴリーに分類されています。  
ここでツールには、ビジュアルファンデーションモデル（VFMs）、API、Pythonなどが含まれます（表2に記載されています）；  
身体的行動は、ロボット[32, 7]や仮想キャラクター[51, 52, 45, 68]などの物理的実体によって実行されます；  
仮想行動[8, 76, 44, 54]には、ウェブタスク（例：リンクをクリックする、スクロールする、キーボードを使用する）が含まれます。  
アプローチに関しては、表1に示されているように、主に2つのタイプがあります。  
最初のタイプは、実行可能な行動についての情報をエージェントに提供するためにプロンプトを使用することを含みます。  
例えば、その時点で利用可能なツールとその機能です；  
二番目のタイプは、行動に関するデータを収集し、この情報を利用してオープンソースの大規模モデル、例えばLLaVA[23]の微調整プロセスを自己指導することを含みます。  
このデータは、通常、GPT-4のような高度なモデルによって生成されます。  
言語のみのエージェントと比較して、行動に関連する情報やデータの複雑さは、学習戦略を最適化するためにより洗練された方法を必要とします。  

![図1](../../../data/14.png)

記憶  
初期の研究では、記憶メカニズムが汎用エージェントの運用において重要な役割を果たすことが示されています。  
人間と同様に、エージェントにおける記憶は長期記憶と短期記憶に分類することができます。  
単純な環境では、短期記憶だけでエージェントが手元のタスクを処理するのに十分です。  
しかし、より複雑で現実的な設定では、長期記憶が不可欠になります。  
表1でわかるように、長期記憶を取り入れているLMAは少数派です。  
言語のみのエージェントとは異なり、これらの多モーダルエージェントは、様々なモダリティを横断して情報を保存できる長期記憶を必要とします。  
いくつかの研究[71, 47, 69, 7]では、すべてのモダリティが記憶のためにテキスト形式に変換されます。  
しかし、[51]では、以前の成功体験をアーカイブするために特別に設計された多モーダル長期記憶システムが提案されています。  
具体的には、これらの記憶はキー値ペアとして保存され、キーは多モーダル状態であり、値は成功した計画です。  
新しい多モーダル状態に遭遇した際には、エンコードされた類似性に基づいて最も類似した例が取り出されます：  

![図1](../../../data/16.png)

ここで、$ k_t $ はCLIPモデルを通じてエンコードされたキーの視覚情報を表し、現在の視覚状態 $ k_x $ との類似性を比較されます。
$ k_x $ もCLIPによってエンコードされます。

$ a^2+b^2=c^2 $  
あ$ a^2+b^2=c^2 $

$\sqrt{3x-1}+(1+x)^2$

$$\sqrt{3x-1}+(1+x)^2$$




















