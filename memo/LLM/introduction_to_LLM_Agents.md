# [Introduction to LLM Agents](https://developer.nvidia.com/blog/introduction-to-llm-agents/)
簡易まとめ：自分の言葉でまとめたもの。  
GPT翻訳：GPTで翻訳した全文。

# 簡易まとめ
LLMで「ある会社の2023年2Qの収支報告のポイントを3つと、技術的な優位性について説明してください」のような質問をする場合、  
単純な検索では実現不可能で、複数の役割に分解して、解答を生成する必要がある。  
このように、複数の動きをすることを可能にするものをLLMエージェントと呼ぶ。  

## What is an AI agent?
「LLMエージェント」には明確な定義はないが、要求を理解し、それを可能にする計画を作成してツールを利用しながら実行するシステムと言える。 
LLMエージェントは、4つのコンポーネントで構成される。
- Agent core
- Memory module
- Tools
- Planning module

![図1](../../data/2.png)

### Agent core
Agent coreは、エージェントの真ん中に位置する調整モジュールであり、コアロジックと行動特性を管理する。  
エージェントとしての目標、利用するツール、計画モジュール(planning module)の記述、過去のやりとりなどの関連情報、エージェントのペルソナ(オプショナル)などを定義する。  

![図2](../../data/3.png)
agent coreのプロンプトの例  

General Instructions: エージェントの目的を記載  
Available tools: 利用できるツールを記載  
Available helpers: 利用できる計画モジュールの説明の記載  
Contextual Information: 関連情報の記載  
Question: 質問の記載  
Answer format: 回答の形式の記載  

### Memory module
Memory moduleは、エージェントの内部ログやユーザーとのやり取りを保持するもの。  
これには、短期記憶と長期記憶の2つがある。  
- 短期記憶  
その時その時のユーザーからの要求への回答を保持する。「思考の流れ」。  
- 長期記憶
ユーザーとエージェント間のやり取りを数週間以上に渡って保持する会話履歴も含んで保持する。  

メモリは、セマンティック検索の結果よりも多くの物を保持する。  
セマンティック検索の類似性や重要性、最新性、その他アプリケーション固有の指標から成る複合スコアを保持する。  
これは、特定の情報を取得するために使用する。  

### Tools
ツールは、目的に特化した外部APIのようなイメージ。  
目的に応じて、利用できるものを用意しておく。  

例えば、  
- RAGパイプライン: コンテキストの取得とそれに基づく回答
- コードインタプリタ: 複雑なプログラムタスクの実行  
- webAPI: インターネット上の情報を検索する
- 天気API: 目的に特化した特定情報の取得  

### Planning module
複雑な質問への回答をするため、タスクを分解することが求められる場合がある。  
また、生成する回答を批判的に見る(検証する)ことで、良い回答を得られる可能性がある。  
このため、以下の機能を持たせる。  

- タスクと質問の分解
- 反省または批評

#### Task and question decomposition(タスクと質問の分解)
「NVIDIAの最後の決算電話会議からの3つのポイントは何でしたか？」という質問への回答を生成する場合、  
以下のように分解したタスクとして捉えることができる。  

- どの技術的なシフトが最も議論されましたか？
- ビジネスの逆風はありますか？
- 財務結果はどうでしたか？

分解の仕方は色々あるため、ここは工夫の余地があるところ。  

#### Reflection or critic(反省または批評)
ReAct、Reflexion、Chain of Thought、Graph of thoughtなどで生成結果をブラッシュアップする。  
ブラッシュアップするだけでなく、実行計画(planning)を洗練するためにも利用できる。  

以上が、LLM Agentを構成する4つのコンポーネント。  

## Agents for enterprise applications
LLM Agentは以下のようなサービスを作れる可能性を持っている。  

- 「データを元に会話する」エージェント
- エージェントのスウォーム(マルチエージェント)
- 推薦および体験デザインエージェント
- カスタマイズされたAI著者エージェント
- マルチモーダルエージェント

### “Talk to your data” agent(「データと話す」エージェント)
「データを元に会話する」のは、単純なRAGパイプラインだけでは以下の点で難しい。  

- ソース文書の意味的類似性
- テーブルのような複雑なデータ構造
- 明白なコンテキストの欠如（すべてのチャンクがそのソースのマーカーを含んでいるわけではない）
- ユーザーが尋ねる質問の複雑さ
- その他

例えば、「2023年Q3から2024年Q1にかけてのデータセンター収入はどのくらい増加しましたか？」という問いには、  
以下の3つに分解して初めて回答ができる。  

1. 2023年Q3のデータセンターの収入は？  
2. 2024年Q1のデータセンターの収入は？  
3. その2つの差は？  

この場合、1つ1つをサブタスクに分解してそれぞれでRAGをしたり、  
サブクエスチョンを正確に扱うためのメモリモジュールにアクセスできる必要がある。  
[LLMパワードエージェント](https://developer.nvidia.com/blog/building-your-first-llm-agent-application/)で説明している。  

### Swarm of agents(マルチエージェント)
複数のエージェントの集合を活用したサービスも可能となる。  

Generative AgentsやChatDevのようなマルチエージェント環境は、低コストで高速に開発できて人気がある。  

CahtDevの例  
![図2](../../data/4.png)  

エージェントのスウォームを使えば、デジタル企業、近隣地域、あるいは町全体を人口で埋めることができ、  
経済研究のための行動シミュレーション、企業のマーケティングキャンペーン、物理インフラのUX要素などのアプリケーションに利用することができます。

これを発展させると、個々の目的のエージェントを組み合わせて、他者や他会社と協力したサービス構築も可能。  

### Agents for recommendation and experience design(推薦および体験デザインエージェント)
購買行動の支援やコンシェルジュ的なサービス。  
例えば、ECサイト上での行動を把握させ、個人にパーソナライズした推薦などが可能となる。  
★こういうのめっちゃ作りてぇえええ!!!!  

### Customized AI author agents(カスタマイズされたAI著者エージェント)
個人用のAI著者。  
共同でメールを書いたり、会議やプレゼンの準備を手伝うサービス。  
エージェントに過去の文章や資料を共有することで、シーンに応じた資料や文章の作成に生かせる。  

### Multi-modal agents(マルチモーダルエージェント)
詳細な内容についての質問は、テキストだけで答えられないこともあるため、テキスト以外のデータを扱いたくなる。  
例えば、売り上げがどれくらい上がったか？はグラフの画像を使ってエージェントに把握してもらったりすると楽。  
このように、テキスト以外にも画像や音声などを一緒に扱ってサービスを構築する。  

![図2](../../data/5.png)

## What’s next?
エージェント周辺の技術エコシステム、実装フレームワーク、必読論文、投稿、関連トピックの概要が知りたければ以下を読むこと。  
- [あなたの最初のエージェントアプリケーションの構築](https://developer.nvidia.com/blog/building-your-first-llm-agent-application/)  
※ フレームワークを使用しないQ&Aエージェントの実装アイディア。  

他のタイプのLLMエージェントについて深く掘り下げるには以下。  
[タスク実行のためのLLMパワードAPIエージェントの構築](https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/)と[データ分析のためのLLMパワードデータエージェントの構築](https://developer.nvidia.com/blog/build-an-llm-powered-data-agent-for-data-analysis/)  

# GPT翻訳
金融アナリストが企業の業績に関する質問に答えるのを助けるために設計された大規模言語モデル（LLM）アプリケーションを考えてみましょう。  
よく設計された検索強化生成（RAG）パイプラインを使用することで、アナリストは「X社の2022会計年度の総収入は何でしたか？」のような質問に答えることができます。  
この情報は、経験豊富なアナリストによって財務諸表から簡単に抽出することができます。  

次に、「2023会計年度の第2四半期の収支報告からの3つのポイントは何でしたか？ 会社が築いている技術的な優位性に焦点を当ててください」という質問を考えてみましょう。  
これは、金融アナリストがレポートに含めたいと考えるタイプの質問ですが、答えるためには時間を投資する必要があります。  

上記のような質問に答える解決策をどのように開発しますか？  
この情報が収支報告からの単純な検索以上のものを要求していることはすぐに明らかです。  
この問いは、計画、特定の焦点、記憶、異なるツールの使用、複雑な質問をよりシンプルなサブパートに分解することを要求します。  
これらの概念を組み合わせたものは、本質的に私たちがLLMエージェントと呼ぶようになったものです。  

この投稿では、LLMを搭載したエージェントについて紹介し、エージェントとは何か、および企業向けアプリケーションの使用例について説明します。  
詳細については、[最初のエージェントアプリケーションの構築(https://developer.nvidia.com/blog/building-your-first-llm-agent-application/)をご覧ください。  
その投稿では、AIエージェントを構築するための利用可能なフレームワークと、質問応答（Q&A）エージェントを実験している人のための入門ガイドをカバーするエコシステムのウォークスルーを提供しています。  

## What is an AI agent?
LLMを搭載したエージェントには広く受け入れられた定義はありませんが、問題を推論し、問題を解決するための計画を作成し、一連のツールの助けを借りて計画を実行できるシステムとして説明することができます。  

簡単に言うと、エージェントは複雑な推論能力、記憶、およびタスクを実行する手段を持ったシステムです。  

この能力は、AutoGPTやBabyAGIのようなプロジェクトで最初に観察されました。  
ここでは、多くの介入なしに複雑な問題が解決されました。  
エージェントをもう少し詳しく説明するために、LLMを搭載したエージェントアプリケーションの一般的なアーキテクチャをここに示します（図1）。

![図1](../../data/2.png)

エージェントは、4つの主要なコンポーネントで構成されています。
- Agent core
- Memory module
- Tools
- Planning module

### Agent core
エージェントコアは、エージェントの中心的な調整モジュールであり、エージェントのコアロジックと行動特性を管理します。  
これをエージェントの「主要な意思決定モジュール」と考えてください。  
また、以下を定義する場所でもあります。  

- エージェントの一般的な目標  
エージェントの全体的な目標と目的を含みます。  

- 実行のためのツール  
本質的にエージェントがアクセスできるすべてのツールの短いリストや「ユーザーマニュアル」です。  

- 異なる計画モジュールの使用方法についての説明  
異なる計画モジュールの有用性についての詳細や、どの状況でどれを使用するかについてです。  

- 関連する記憶  
これは、推論時にユーザーとの過去の会話から最も関連性の高い記憶項目を記録する動的なセクションです。  
「関連性」は、ユーザーが尋ねる質問を使用して決定されます。  

- エージェントのペルソナ（オプション）
このペルソナの説明は、一般的に、モデルに特定のタイプのツールの使用を優先するようにバイアスをかけるか、またはエージェントの最終的な反応に典型的な特異性を付与するために使用されます。  

![図2](../../data/3.png)

### Memory module
AIエージェントにおいて、メモリモジュールは重要な役割を果たします。  
メモリモジュールは、基本的にはエージェントの内部ログおよびユーザーとの相互作用の保存庫と考えることができます。  

メモリモジュールには2種類あります：  
- 短期記憶  
エージェントがユーザーからの単一の質問に答えようとする際に経験する行動や考えの台帳。  
エージェントの「思考の流れ」です。  

- 長期記憶  
ユーザーとエージェントの間で起こるイベントについての行動や考えの台帳。  
数週間または数ヶ月にわたる会話履歴を含むログブックです。  

メモリは、意味的類似性に基づく検索以上のものを要求します。  
通常、意味的類似性、重要性、最新性、その他のアプリケーション固有の指標から成る複合スコアが作成されます。  
これは、特定の情報を取得するために使用されます。  

### Tools
ツールは、エージェントがタスクを実行するために使用できる、よく定義された実行可能なワークフローです。  
多くの場合、それらは特化したサードパーティのAPIと考えることができます。  

例えば、エージェントはRAGパイプラインを使用してコンテキストを意識した回答を生成したり、複雑なプログラムタスクを解決するためにコードインタープリターを使用したり、  
インターネット上の情報を検索するためのAPIを使用したり、あるいは天気APIやインスタントメッセージングアプリケーションのような単純なAPIサービスを使用することができます。

### Planning module
複雑な問題、例えば一連の財務報告を分析して層になったビジネスの質問に答える場合などは、繊細なアプローチがしばしば必要とされます。  
LLM（Large Language Model）を活用したエージェントを用いることで、この複雑さは以下の2つの技術の組み合わせによって扱うことができます  

- タスクと質問の分解
- 反省または批評

#### Task and question decomposition
複合的な質問や推論される情報は、ある種の分解を必要とします。  
例えば、「NVIDIAの最後の決算電話会議からの3つのポイントは何でしたか？」という質問を考えてみましょう。  

この質問に答えるために必要な情報は、1時間に及ぶ会議の文字起こしから直接抽出することはできません。  
しかし、問題は複数の質問トピックに分解することができます：  

- どの技術的なシフトが最も議論されましたか？
- ビジネスの逆風はありますか？
- 財務結果はどうでしたか？

これらの各質問はさらに細分化することができます。  
とは言え、この分解を導くためには、専門的なAIエージェントが必要です。  

#### Reflection or critic
ReAct、Reflexion、Chain of Thought、Graph of thoughtのような技術は、批評家または証拠に基づくプロンプティングのフレームワークとして機能してきました。  
これらは、LLMの推論能力と応答を改善するために広く使用されてきました。  
これらの技術は、エージェントによって生成された実行計画を洗練するためにも使用できます。

## Agents for enterprise applications
エージェントの応用は実質的に無限ですが、以下に挙げるいくつかの興味深いケースは、多くのビジネスに大きな影響を与える可能性があります：

- 「データと話す」エージェント
- エージェントのスウォーム(マルチエージェント)
- 推薦および体験デザインエージェント
- カスタマイズされたAI著者エージェント
- マルチモーダルエージェント

### “Talk to your data” agent
「データと話す」というのは単純な問題ではありません。  
直接的なRAGパイプラインでは解決できない多くの課題があります：  

- ソース文書の意味的類似性
- テーブルのような複雑なデータ構造
- 明白なコンテキストの欠如（すべてのチャンクがそのソースのマーカーを含んでいるわけではない）
- ユーザーが尋ねる質問の複雑さ
- その他

例えば、以前の決算コールの文字起こしの例（2023年Q3 | 2024年Q1）に戻ります。  
次の質問にどうやって答えますか？  
「2023年Q3から2024年Q1にかけてのデータセンター収入はどのくらい増加しましたか？」  
この質問に答えるためには、基本的に3つの質問に個別に答える必要があります（つまり、計画モジュールが必要です）：

1. 2023年Q3のデータセンターの収入はいくらでしたか？  
2. 2024年Q1のデータセンターの収入はいくらでしたか？  
3. その2つの差は何でしたか？  

この場合、質問の分解を行い（サブクエスチョンを生成して、より大きな問題が解決されるまで答えを探す）、  
具体的な情報を取得するために使用されるRAGパイプライン（ツールとして使用）、  
およびサブクエスチョンを正確に扱うためのメモリモジュールにアクセスできるエージェントが必要になります。  
[LLMパワードエージェント](https://developer.nvidia.com/blog/building-your-first-llm-agent-application/)で、このタイプのケースについて詳細に説明しています。  

### Swarm of agents
エージェントのスウォームは、単一の環境内で共存しながら協力して問題を解決するために一緒に働くエージェントの集合として理解できます。  
分散型のエージェントのエコシステムは、問題を解決するために連携して使用される複数の「スマート」マイクロサービスに非常に似ています。  

Generative AgentsやChatDevのようなマルチエージェント環境は、コミュニティに非常に人気があります（図3）。  
なぜでしょうか？ChatDevのようなフレームワークを使うと、エンジニア、デザイナー、プロダクトマネジメント、CEO、エージェントのチームを組んで、低コストで基本的なソフトウェアを構築できます。  
Brick BreakerやFlappy Birdのような人気ゲームは、わずか50セントでプロトタイプを作成できます！  

エージェントのスウォームを使えば、デジタル企業、近隣地域、あるいは町全体を人口で埋めることができ、  
経済研究のための行動シミュレーション、企業のマーケティングキャンペーン、物理インフラのUX要素などのアプリケーションに利用することができます。

![図2](../../data/4.png)

これらのアプリケーションは現在、LLMなしではシミュレーションすることが不可能であり、実世界で実行するには非常に高額です。  

### Agents for recommendation and experience design
インターネットは推薦によって機能しています。  
エージェントによって動かされる会話型推薦システムを使用して、パーソナライズされた体験を作り出すことができます。  

例えば、eコマースウェブサイト上のAIエージェントが、あなたの一般的なリクエストや選択に基づいて商品を比較し、推薦を提供することを考えてみてください。  
コンシェルジュのような完全な体験も、複数のエージェントが最終ユーザーをデジタルストアをナビゲートするのを手助けすることで構築できます。  
どの映画を観るか、どのホテルの部屋を予約するかのような体験を、単なる決定ツリースタイルの会話の連続ではなく、会話として作り出すことができます！  

### Customized AI author agents
もう一つの強力なツールは、個人用のAI著者を持つことです。  
これは、共同でメールを執筆したり、時間に敏感な会議やプレゼンテーションの準備を手伝ってくれるようなタスクに役立ちます。  
通常の著作ツールの問題点は、異なるタイプの資料を様々な聴衆に合わせてカスタマイズする必要があることです。  
例えば、投資家へのピッチは、チームプレゼンテーションとは異なる言葉遣いでなければなりません。  

エージェントはあなたの過去の作業を活用することができます。  
その後、エージェントにあなたの個人的なスタイルに合わせてエージェントが生成したピッチを形成させ、特定の使用ケースとニーズに応じて作業をカスタマイズさせます。  
このプロセスは、一般的なLLMの微調整には繊細すぎることが多いです。  

### Multi-modal agents
テキストのみを入力として使用する場合、実際には「データと話す」ことはできません。  
上述した使用例は、画像や音声ファイルなど、さまざまな入力を消化できるマルチモーダルエージェントを構築することで拡張できます。

![図2](../../data/5.png)

これらは、企業の課題を解決するために追求できる方向性のほんのいくつかの例です。  
データキュレーション、ソーシャルグラフ、ドメイン専門知識のためのエージェントは、すべて企業アプリケーションのために開発コミュニティによって追求されている活動的な領域です。  

## What’s next?
LLM（Large Language Model）を活用したエージェントは、複雑な推論スキルを持っている点で典型的なチャットボットアプリケーションとは異なります。  
エージェントコア、メモリモジュール、ツールセット、計画モジュールから構成されるエージェントは、データキュレーションから高度なeコマース推薦システムに至るまで、  
さまざまな企業設定で高度にパーソナライズされた回答やコンテンツを生成することができます。  

エージェント周辺の技術エコシステム、実装フレームワーク、必読論文、投稿、関連トピックの概要については、  
[あなたの最初のエージェントアプリケーションの構築](https://developer.nvidia.com/blog/building-your-first-llm-agent-application/)をご覧ください。  
フレームワークを使用しないQ&Aエージェントの実装のウォークスルーは、データとのコミュニケーションをより良くするのに役立ちます。  

他のタイプのLLMエージェントについて深く掘り下げるには、[タスク実行のためのLLMパワードAPIエージェントの構築](https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/)と[データ分析のためのLLMパワードデータエージェントの構築](https://developer.nvidia.com/blog/build-an-llm-powered-data-agent-for-data-analysis/)をご覧ください。

## 単語
- tailored focus: 適切な焦点
- earnings call: 収支報告
- In short: 要するに(簡単にいうと)
- ledger: 台帳